# LangChain Features - Quick Start Guide

## ğŸš€ Get Started in 3 Steps

### Step 1: Start Ollama (Optional - for RAG features)

```powershell
# In a PowerShell terminal
ollama serve
```

> **Note:** Conversational Memory works without Ollama! Only RAG semantic search requires it.

### Step 2: Launch the App

```powershell
# In the project directory
streamlit run gui/app.py
```

### Step 3: Enable Features

In the Streamlit sidebar, under **ğŸ§  LangChain Features**:

- â˜‘ï¸ Check **ğŸ’¬ Conversational Memory**
- â˜‘ï¸ Check **ğŸ“š RAG Variable Search** (if Ollama running)

---

## ğŸ’¬ Try a Conversation

### Example 1: Simple Follow-Up

```
You: "What are the top 5 census tracts in Orleans Parish by median income?"

Bot: [Shows top 5 tracts]

You: "Now show me poverty rate"

Bot: ğŸ”„ Follow-up question detected!
     Using context from previous query: Parish: Orleans Parish
     [Shows poverty rate for Orleans Parish]
```

### Example 2: Changing Geography

```
You: "Show me the highest income tracts in Orleans Parish"

Bot: [Shows Orleans results]

You: "What about Lafayette Parish instead?"

Bot: ğŸ”„ Follow-up question detected!
     [Shows Lafayette results for same measure]
```

### Example 3: Exploring Different Measures

```
You: "Find tracts with low poverty in St. Tammany Parish"

Bot: [Shows poverty results for St. Tammany]

You: "Also show population density"

Bot: ğŸ”„ Follow-up question detected!
     [Shows population density for St. Tammany]
```

---

## ğŸ¯ Features at a Glance

### Conversational Memory ğŸ’¬

**What it does:** Remembers context from previous queries

**When to use:**

- Exploring different measures in the same parish
- Comparing multiple parishes for the same measure
- Asking follow-up questions without repeating yourself

**Patterns it understands:**

- "Now show me..."
- "Also show..."
- "What about..."
- "Instead of..."
- "Same for..."

### RAG Variable Search ğŸ“š

**What it does:** Uses semantic search to find better Census variables

**When to use:**

- Query uses synonyms or informal terms
- Not sure of exact Census terminology
- Want better variable suggestions

**Examples:**

- "household earnings" â†’ Finds B19013 (Median Household Income)
- "poor people" â†’ Finds S1701 (Poverty Status)
- "people living in apartments" â†’ Finds B25024 (Units in Structure)

---

## ğŸ“Š Visual Indicators

### When Memory is Active

```
ğŸ§  LangChain Features Active: ğŸ’¬ Memory
```

### When Follow-Up Detected

```
ğŸ”„ Follow-up question detected!
Using context from previous query: Parish: Orleans Parish
```

### When RAG Finds Matches

```
ğŸ“š RAG Variable Suggestions â–¼
   B19013_001E (score: 0.95)
   Median household income in the past 12 months...
```

### Conversation History

Click **ğŸ“œ Conversation Context** in sidebar to see:

```
Previous queries:
1. Query: "What are the top 5 tracts in Orleans by income?"
   Parish: Orleans Parish
   Measure: median household income
   Results: 5 tracts

Current context:
Parish: Orleans Parish
Measure: median household income
```

---

## ğŸ”§ Troubleshooting

### "RAG system unavailable"

**Cause:** Ollama is not running

**Solution:**

```powershell
# Start Ollama
ollama serve

# Verify it's running
ollama ps
```

### "Follow-up not detected"

**Cause:** Conversational Memory is disabled

**Solution:**

- Check â˜‘ï¸ **Conversational Memory** in sidebar
- Make sure previous query was successful (stores context)

### Clear conversation history

**When:** Want to start fresh, or memory has wrong context

**How:** Click **ğŸ—‘ï¸ Clear Conversation** button in sidebar

---

## âš™ï¸ Configuration

### Memory Settings

- **Max history:** 10 queries (default)
- **Persistence:** In-memory only (clears on restart)
- **Storage:** ~1 KB per query

### RAG Settings

- **Vector store:** `./chroma_db` directory
- **First build:** 30-60 seconds
- **Subsequent loads:** <1 second
- **Storage:** ~50-100 MB

---

## ğŸ“ Tips & Best Practices

### 1. Use Natural Language

âœ… Good: "Now show me poverty rate"  
âŒ Avoid: "Query: S1701_C03_001E for FIPS 071"

### 2. Build on Previous Queries

âœ… Good conversation flow:

```
"Top 5 tracts in Orleans by income"
â†’ "Now show poverty rate"
â†’ "What about Lafayette instead?"
```

âŒ Repetitive:

```
"Top 5 tracts in Orleans by income"
â†’ "Top 5 tracts in Orleans by poverty rate"
â†’ "Top 5 tracts in Lafayette by poverty rate"
```

### 3. Clear Memory When Switching Topics

If you switch to a completely different analysis:

- Click **ğŸ—‘ï¸ Clear Conversation**
- Start fresh without old context

### 4. Enable Memory for Exploratory Analysis

Best for:

- Comparing multiple measures in one parish
- Exploring different parishes for one measure
- Interactive data exploration sessions

Disable for:

- One-off queries
- Automated/scripted queries
- When you want independent queries

---

## ğŸ“š Learn More

- **Full Documentation:** `docs/LANGCHAIN_FEATURES.md`
- **Implementation Details:** `docs/LANGCHAIN_IMPLEMENTATION_SUMMARY.md`
- **Test Examples:** `test_langchain_integration.py`

---

## ğŸ†˜ Need Help?

### Check the Conversation History

Expand **ğŸ“œ Conversation Context** in sidebar to see what the system remembers

### View Debug Output

Enable **"Show detailed output"** in Settings to see:

- LLM reasoning
- Variable selection process
- Geography resolution
- RAG search results

### Common Issues

**Q: Follow-ups don't work**  
A: Make sure Conversational Memory is â˜‘ï¸ checked

**Q: Wrong variables selected**  
A: Enable RAG Variable Search for better semantic matching

**Q: RAG is slow**  
A: First run builds vector store (30-60s). Subsequent runs are fast (<1s)

**Q: Memory has wrong context**  
A: Click "ğŸ—‘ï¸ Clear Conversation" to start fresh

---

**Ready to explore Louisiana Census data with conversational AI! ğŸ‰**
